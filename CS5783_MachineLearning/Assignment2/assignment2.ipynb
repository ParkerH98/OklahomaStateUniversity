{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def sigmoid(a):\n",
    "    return (np.exp(a) / (1 + (np.exp(a))))\n",
    "\n",
    "def d_sigmoid(a):\n",
    "    return sigmoid(a) * (1 - sigmoid(a))\n",
    "\n",
    "def identity(a):\n",
    "    return np.dot(1, a)\n",
    "\n",
    "def d_identity(a):\n",
    "    a = 1\n",
    "    return a\n",
    "\n",
    "def mean_square_error(y_predicted, y_actual):\n",
    "    return np.mean((y_predicted - y_actual) ** 2)\n",
    "\n",
    "def d_mean_square_error(y_predicted, y_actual):\n",
    "    return 2 * (y_predicted - y_actual)\n",
    "\n",
    "X_train = np.loadtxt(\"X_train.csv\")\n",
    "Y_train = np.loadtxt(\"Y_train.csv\")\n",
    "X_test = np.loadtxt(\"X_test.csv\")\n",
    "Y_test = np.loadtxt(\"Y_test.csv\")\n",
    "Y_train = np.reshape(Y_train, (100, 1))\n",
    "\n",
    "# initializing weights and biases\n",
    "np.random.seed(1)\n",
    "w1 = np.random.rand(2, 2)\n",
    "w2 = np.random.rand(2, 1)\n",
    "b1 = np.random.rand(1, 1)\n",
    "b2 = np.random.rand(1, 1)\n",
    "\n",
    "learning_rate = .001\n",
    "\n",
    "for i in range(10000):\n",
    "    \n",
    "    # original product of input layer and activation output\n",
    "    z1 = np.dot(X_train, w1) + b1\n",
    "    a1 = sigmoid(z1)\n",
    "\n",
    "    # original product of hidden layer and activation output\n",
    "    z2 = np.dot(a1, w2) + b2\n",
    "    a2 = identity(z2)\n",
    "    \n",
    "    loss = mean_square_error(a2, Y_train)\n",
    "    \n",
    "    dL2 = 2 * (a2 - Y_train)\n",
    "    da2 = d_identity(z2)\n",
    "    dz2 = a1\n",
    "    da1 = d_sigmoid(z1)\n",
    "    dz1 = X_train\n",
    "    \n",
    "    dw2 = np.dot(a1.T, dL2 * d_identity(a2))\n",
    "    dw1 = np.dot(X_train.T, (np.dot(dL2 * d_sigmoid(a2), w2.T) * d_sigmoid(a1)))\n",
    "    db2 = dL2\n",
    "    db1 = np.dot(dL2 * d_sigmoid(a2), w2.T) * d_sigmoid(a1)\n",
    "    \n",
    "    w2 = w2 - (dw2 * learning_rate)\n",
    "    w1 = w1 - (dw1 * learning_rate)\n",
    "    b2 = b2 - (db2 * learning_rate)\n",
    "    b1 = b1 - (db1 * learning_rate)\n",
    "    \n",
    "    if (i % 500 == 0):\n",
    "            print(\"Iteration {}: Cost: {}\".format(i, loss))\n",
    "    if (loss < .00001):\n",
    "        print(\"Iteration {}: Cost: {}\".format(i, loss))\n",
    "        break"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Iteration 0: Cost: 5708.4887710854055\n",
      "Iteration 500: Cost: 447.771980249121\n",
      "Iteration 1000: Cost: 60.46188803540208\n",
      "Iteration 1500: Cost: 8.117407470657511\n",
      "Iteration 2000: Cost: 1.0982064803116496\n",
      "Iteration 2500: Cost: 0.1788791680010136\n",
      "Iteration 3000: Cost: 0.04330329003523548\n",
      "Iteration 3500: Cost: 0.011227615240694731\n",
      "Iteration 4000: Cost: 0.0025768673290886917\n",
      "Iteration 4500: Cost: 0.0005242282244847348\n",
      "Iteration 5000: Cost: 9.758209810607952e-05\n",
      "Iteration 5500: Cost: 1.7049679877851675e-05\n",
      "Iteration 5651: Cost: 9.970132086475612e-06\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.7",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.7 64-bit"
  },
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}