{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "# Load the TensorBoard notebook extension.\n",
    "%load_ext tensorboard\n",
    "\n",
    "from datetime import datetime\n",
    "from packaging import version\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflow.keras.layers as Layer\n",
    "\n",
    "import tensorboard\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset and normalize\n",
    "(train_images, train_labels), (test_images, test_labels) = keras.datasets.mnist.load_data()\n",
    "train_images = train_images / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Invalid keyword argument(s) in `compile`: {'learning_rate'}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/yq/sm28v1tn1ll9ymq1bh36sv300000gn/T/ipykernel_58167/3568094742.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mcnn_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mActivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'softmax'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0mcnn_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sparse_categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'.01'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0mcnn_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0mcnn_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(self, optimizer, loss, metrics, loss_weights, weighted_metrics, run_eagerly, steps_per_execution, **kwargs)\u001b[0m\n\u001b[1;32m    553\u001b[0m       \u001b[0mfrom_serialized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'from_serialized'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_compile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    556\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_eagerly\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_eagerly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_validate_compile\u001b[0;34m(self, optimizer, metrics, **kwargs)\u001b[0m\n\u001b[1;32m   2715\u001b[0m     \u001b[0minvalid_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'sample_weight_mode'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2716\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minvalid_kwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2717\u001b[0;31m       raise TypeError('Invalid keyword argument(s) in `compile`: %s' %\n\u001b[0m\u001b[1;32m   2718\u001b[0m                       (invalid_kwargs,))\n\u001b[1;32m   2719\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Invalid keyword argument(s) in `compile`: {'learning_rate'}"
     ]
    }
   ],
   "source": [
    "x_train = train_images.reshape(-1, 28, 28, 1) #add an additional dimension to represent the single-channel\n",
    "x_test = test_images.reshape(-1, 28, 28, 1)\n",
    "\n",
    "cnn_model = tf.keras.models.Sequential(name='CNN_Increasing_Filters')\n",
    "\n",
    "cnn_model.add(Layer.Conv2D(8, (3, 3), padding='same', activation='relu', name='Conv_Layer_1')) # conv layer 1\n",
    "cnn_model.add(Layer.Conv2D(9, (3, 3), padding='same', activation='relu', name='Conv_Layer_2')) # conv layer 2\n",
    "cnn_model.add(Layer.Conv2D(10, (3, 3),padding='same', activation='relu', name='Conv_Layer_3')) # conv layer 3\n",
    "cnn_model.add(Layer.MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n",
    "\n",
    "cnn_model.add(Layer.Conv2D(20, (3, 3), padding='same', activation='relu', name='Conv_Layer_4')) # conv layer 4\n",
    "cnn_model.add(Layer.Conv2D(21, (3, 3), padding='same', activation='relu', name='Conv_Layer_5')) # conv layer 5\n",
    "cnn_model.add(Layer.Conv2D(22, (3, 3),padding='same', activation='relu', name='Conv_Layer_6')) # conv layer 6\n",
    "cnn_model.add(Layer.MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n",
    "\n",
    "cnn_model.add(Layer.Conv2D(44, (3, 3), padding='same', activation='relu', name='Conv_Layer_7')) # conv layer 7\n",
    "cnn_model.add(Layer.Conv2D(45, (3, 3), padding='same', activation='relu', name='Conv_Layer_8')) # conv layer 8\n",
    "cnn_model.add(Layer.Conv2D(46, (3, 3), padding='same', activation='relu', name='Conv_Layer_9')) # conv layer 9\n",
    "cnn_model.add(Layer.MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n",
    "\n",
    "cnn_model.add(Layer.Conv2D(92, (3, 3), padding='same', activation='relu', name='Conv_Layer_10')) # conv layer 10\n",
    "\n",
    "cnn_model.add(Layer.Flatten())\n",
    "cnn_model.add(Layer.Dense(184))\n",
    "cnn_model.add(Layer.Activation('relu'))\n",
    "cnn_model.add(Layer.Dense(10))\n",
    "cnn_model.add(Layer.Activation('softmax'))\n",
    "\n",
    "cnn_model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "cnn_model.build(input_shape=(1,28,28,1))\n",
    "cnn_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-17 16:31:59.336705: I tensorflow/core/profiler/lib/profiler_session.cc:131] Profiler session initializing.\n",
      "2021-10-17 16:31:59.336728: I tensorflow/core/profiler/lib/profiler_session.cc:146] Profiler session started.\n",
      "2021-10-17 16:31:59.337243: I tensorflow/core/profiler/lib/profiler_session.cc:164] Profiler session tear down.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1/118 [..............................] - ETA: 4:10 - loss: 2.3025 - accuracy: 0.1289"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-17 16:32:01.702607: I tensorflow/core/profiler/lib/profiler_session.cc:131] Profiler session initializing.\n",
      "2021-10-17 16:32:01.702628: I tensorflow/core/profiler/lib/profiler_session.cc:146] Profiler session started.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2/118 [..............................] - ETA: 45s - loss: 2.3020 - accuracy: 0.1650 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-17 16:32:02.124746: I tensorflow/core/profiler/lib/profiler_session.cc:66] Profiler session collecting data.\n",
      "2021-10-17 16:32:02.126275: I tensorflow/core/profiler/lib/profiler_session.cc:164] Profiler session tear down.\n",
      "2021-10-17 16:32:02.128199: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: logs/fit/20211017-163159/train/plugins/profile/2021_10_17_16_32_02\n",
      "\n",
      "2021-10-17 16:32:02.129587: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for trace.json.gz to logs/fit/20211017-163159/train/plugins/profile/2021_10_17_16_32_02/Parkers-MacBook-Pro.local.trace.json.gz\n",
      "2021-10-17 16:32:02.134231: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: logs/fit/20211017-163159/train/plugins/profile/2021_10_17_16_32_02\n",
      "\n",
      "2021-10-17 16:32:02.134487: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for memory_profile.json.gz to logs/fit/20211017-163159/train/plugins/profile/2021_10_17_16_32_02/Parkers-MacBook-Pro.local.memory_profile.json.gz\n",
      "2021-10-17 16:32:02.135887: I tensorflow/core/profiler/rpc/client/capture_profile.cc:251] Creating directory: logs/fit/20211017-163159/train/plugins/profile/2021_10_17_16_32_02\n",
      "Dumped tool data for xplane.pb to logs/fit/20211017-163159/train/plugins/profile/2021_10_17_16_32_02/Parkers-MacBook-Pro.local.xplane.pb\n",
      "Dumped tool data for overview_page.pb to logs/fit/20211017-163159/train/plugins/profile/2021_10_17_16_32_02/Parkers-MacBook-Pro.local.overview_page.pb\n",
      "Dumped tool data for input_pipeline.pb to logs/fit/20211017-163159/train/plugins/profile/2021_10_17_16_32_02/Parkers-MacBook-Pro.local.input_pipeline.pb\n",
      "Dumped tool data for tensorflow_stats.pb to logs/fit/20211017-163159/train/plugins/profile/2021_10_17_16_32_02/Parkers-MacBook-Pro.local.tensorflow_stats.pb\n",
      "Dumped tool data for kernel_stats.pb to logs/fit/20211017-163159/train/plugins/profile/2021_10_17_16_32_02/Parkers-MacBook-Pro.local.kernel_stats.pb\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118/118 [==============================] - 45s 364ms/step - loss: 0.5946 - accuracy: 0.8086\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 12.8783 - accuracy: 0.9661\n",
      "Test loss: 12.87834358215332\n",
      "Test accuracy: 0.9660999774932861\n"
     ]
    }
   ],
   "source": [
    "# Define the Keras TensorBoard callback.\n",
    "logdir=\"logs/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "\n",
    "model1 = cnn_model\n",
    "# Train the model.\n",
    "model1.fit(\n",
    "    x_train,\n",
    "    train_labels, \n",
    "    batch_size=512,\n",
    "    epochs=1,\n",
    "    callbacks=[tensorboard_callback])\n",
    "\n",
    "\n",
    "# Evaluate\n",
    "score = model1.evaluate(x_test, test_labels)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "# Test loss: 43.735774993896484\n",
    "# Test accuracy: 0.8974000215530396"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
